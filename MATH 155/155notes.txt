NOTES FOR 155

types of samples

simple random sample - size n, chosen by method in which each sample of size n has equal chance of being selected, and is representative
random sample - sample chosen by method in which individual in population has equal chance of being selected

convenience sample - sample thats not drawn by well define method (if does not differe systematically, it is ok)

statififed sampling - population is divided into groups (strata) that differ, groups are alike in some way

cluster - population is divided into groups (clusters0 that are heterogenous, randomly select clusters for our sample (useful in large pop.)

systematic - items ordered, every kth item is chosen

volunatry response (not reliable)

----

Qualitative: classify data into categories
  ordinal: has a natural order
  nominal: has no natural order


Quantitative: Numeric, how much
  discrete: variable whose possible values can be listed or counted
  continuous: variable that can assume any value on an interval

DESIGN OF EXPERIMENTS

experimental unit - individual which is studied
outcome response - what is measured of each experimental unit
treatments - procedure applied to each experimental unit

parameter - number that describes population
e.g. average age of employees at factory is 30

staticstic - number that describes sample
e.g. 57% of respondants support change

----

Graphs

stem/leaf - put first digit on left of line, other digits on right
dot plot - write values below, put dot for every instance of value

frequency distribution
Frequency distributions for quantitative data are just like those for qualitative data
except that the data are divided into classes rather than categories.

relative frequency = frequency / sum of all frequencies

The cumulative frequency of a class is the sum of the frequencies of that class and all previous classes.
cumulative relative frequency = cumulative freq. / sum al off freqs.

pie chart - multiple relative frequencies by 360 to get angle of each


Frequency Polygon - get midpoints of each class (for freq. distribution), put on x-axis, frequency on y-axis
relative frequency polygon - same, except use relative frequency on y-axis

Ogive - constructed by plotting a point for each class, x-coord is the the upper class limit. Y-coord is the cumulative freq. points connected by line


----

Observational Study
Study wehre assignment to treatment group is not done by investigator

In a perfrect study, groups would not differ in any way except how they recieve treatement
In practice, not possible, randomization is next best thing

If large difference, can conclude likely due to treatment

Cofounding
Could be other factors influencing result

Outcome variable
what is being measured after treatement

Cohort
Group of people linked in some way

Case controlled
Study that compares subjects belonging to two different groups

Cohort study
Group of subjects to determine if factor of interest are associated with an outcome

Prospective cohort study - subjects followed over time
Cross sectional - measurements taken at one point in time
Retrospective - observational study where cases have happened before study takes place

BIAS

Example: if we draw a simple random sample for a study, may not be accruate, average many simple random samples

Voluntary Response bias - willing to respond/stronger opinions

self interest bias - something to gain/incentive to be bias

social acceptability bias - people reluctant to admit behavior that will reflect bad on them

leading question bias - question worded to suggest a particular response

non response bias - many people will refuse to answer quetions (non responders)

sampling bias - some members of population likely to be included in the sample than others

-------

Empirical rule
applies to bell shaped distribution
gives approx. percentage of values that fall within standard deviation from mean
68% within 1sd
95% within 2sd
99.9% within 3sd

Chevyhev's Theorom
Applies to any dataset. Gves a lower bound for percentages of values that are within a certain number of standard devs from mean
At least 75% within 2sd
At least 89% within 3sd

Coefficient of variation
CV - tells how large the standard deviation is relative to the mean (standard dev/mean)

Measures of Position

Five Number Summary:
min, max, Q1, median, Q3

Description of relative standing of a certain data value within entire data set
The standard score (z score) represents distance value is from the mean

Percentiles - divivde dataset into 100 parts (e.g. 27% percentile)

to find percentile, (e.g. P58 for 58th percentile) compute Locator 
Compute locater L using formula:

L = k/100(n) 

(n=number of values in dataset)

If L is an integer then Pk = (Lth value + (L+1)th value) / 2
If L is not an integer then round up to the next larger integer

E.G. Find 78th percentile. Assume 85 values in dataset (n = 85)
L = (78/100) * 85 = 66.3 ~ 67 (always round up)
Value of 78th percentile is in position 67

Assume n = 85 again
FOR median(Q2): (50/100) * 85 = 15, 15 is an integer, so median would be average of values in positions 15 and 16
(in case of our dataset, position 15 and 16 are 20 and 21, so median would be (20 + 21)/2 = 20.5
IF L was not an integer, simply round up, position in that spot is median

Q1 = .25 * n
Q2 = median
Q3 = .75 * n
NOTE, output will be the positions of the values, not the values themselves

IQR = Q3 - Q1
Lower outlier bound = Q1 - 1.5 * IQR
Upper outlier bound = Q3 + 1.5 * IQR

Box plot:
|------|-----|----|---------|    *
LOB    Q1    Med.  Q3       UOB   Outlier

LOB = lower outlier bound
OUB = upper outlier bound

Given value x, find percentile:
-assume N values in dataset
-arrange data in increasing order
Percentile = 100 * ((Number of vals less than x) + .5) / N

E.G) Assume datset has 40 values, assume value we have has 23 values less than it:
Percentile is 100 * (23 + .5) / 40 = 58.75 ~ 59 (round up)

Z score = (x - u) / o where x = value, u = mean, o = standard deviation

IF z-score given, finding value:
x = u + (z*o)

EVENTS
Compound events
an event formed by combining two or more events, Events A or B (inclusive) either A or B or both occurs
Events A and B - A and B occur

Probability model - sum of all probabilities must be 1

Probabillity of (A or B) = P(A)+P(B) - P(A and B)
Mutually exclusive - two events cannot happen at same time
IF events A and B are mutually exclusive, then P(A or B) = P(A) + P(B)

P(A or B) = P(A) + P(B) - P(A AND B)
IF A and B are mutually exclusive, P(A or B) + P(A) + P(B)

These two are equivolent
P(A and B) = P(A) P(B | A)
P(A and B) = P(B) P(A | B)

IF A and B are independent events
P(A and B) = P(A)P(B)

Sequence of Events (probability of A, B, C in order)
P(Sequence) = P(A)P(B)P(C)

Compliment of event A is that A does not occur
Compliment: P(A^c) = 1 - P(A)

Correlation Coefficient (r)
Given X, Y, make table containing X, Y, XY, X^2, Y^2
Take summation of each column
Pretend E is summation
r = (n * Exy - Ex * Ey) / Sqrt((n * Ex^2 - (Ex)^2)(n * Ey^2 - (Ey)^2)

If r is positive, there is a positive correlation (as X increases, Y increases)

Least Squares Regression Line (like correlation coefficent for graphs)
Given X, Y, make table, find mean of X values, mean of Y values
Then, add columns for X-Xavg and Y-Yavg
Then, add columns, (X-Xavg)^2, and column (X-Xavg)(Y-Yavg)
Add up last two columns, the (X-Xavg)^2 is Denominator, column (X-Xavg)(Y-Yavg) is Numerator, fraction (decimal) is B1
B0 formula: Yavg = B0 + B1(Xavg)
Yhat = B0 + B1x

The law of large numbers says that as a probability experiment is repeated again and again, 
the proportion of times that a given event occurs will approach its probability.

A sample space contains all the possible outcomes of a probability experiment.
E.g. The toss of a coin Sample Space: two possible outcomes: Heads and Tails. So a sample space is {Heads, Tails}.

Empirical Method consists of repeating an experiment a large number of times, and using the proportion of times an outcome occurs to approximate the probability of the outcome.

Hyptothesis Testing

Type I error - reject Hypoth, but if actually true, Alpha = P(type I error)
Type II error - fail to reject Hypoth, when is actually false Beta = P(type II error)

See table from 11-23

Confidence Intervals

Population with low variation leads to similar samples with low variation, leads to narrow confidence interval
Lots of variation leads to varied samples with high variation, leads to wider confidence interval

For Exam III:
HW 6 - probability, events
HW 7 - counting, permutations, combinations, some binomial experiments
HW 8 - area under curve, z-values, cumulative normal dist. table, mean/std.dev, percentiles for norm. dists.
HW 9 - find U-x given U, sample size drawn given mean and std. dev, cumulative normal dist. table
HW 10 - critical values for confidence intervals, margin of error, conf. int. for given mean, 

Sample test answers

ask banks to go over 5, 6, 9

#3 (refer to hw 10, question 5-8)
n = 40
x = 82
s = 26
conf = .99
freedom = n - 1 = 39
critical value is given, c (sometimes given as t or z(alpha/2) ) = 2.575

compute margin of error (e) : c * (s / sqrt(n)) = 2.575 * (26 / Sqrt(40)) = 10.5857 = 10.59

get the conf. interval by x - e < u < x + e
= 82 - 10.59 < u < 82 + 10.59
= 71.41, 92.59





#4 (hw 8, question 8-11)
u = 200
o = 50
probability of being between 170 to 220

Find z scores for x = 170, x = 220
x = 170, z = -.6
x = 220, z = .4

Next, on normal curve, find area between z scores -.6 and .4 (using zscorecalculator.com)
left z score = -.6, right = .4, area = .381169





#7 (similar to 3, refer to HW 10)

n = 225
x = 32.5
s = 30

conf = .95
freedom = n - 1 = 39

To get critical value, use bottom row of T-Dist. table, see that for 95%, c = 1.960
find margin of error = c * (s / Sqrt(n)) = 1.96 * (30 / Sqrt(225)) = 32.5 +or- 3.92 = (28.58, 36.42)

To estimate U (x) to within .5 with 95% confidence:

(c * s^2)
--------- = (1.96^2 / 30^2) / .5^2 = 13829.8 = 13830 sample size
    e^2



#11

Use a binomial distribution calc
n = 8
p = .3
